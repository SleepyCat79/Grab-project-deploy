{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔎 Crawling page 1...\n",
      "https://hanoitourist.vn/can-tho-soc-trang-con-dao\n",
      "✅ CẦN THƠ - SÓC TRĂNG - CÔN ĐẢO\n",
      "📍 Ngày đi: 19/04, 17/05, 20/06/2025... (4 ngày 3 đêm) | 📅 Hành trình: TP. Hồ Chí Minh - Cần Thơ - Côn Đảo - 4 ngày 3 đêm | 💰 8,790,000đ\n",
      "📝 Lịch trình: NGÀY 01: HÀ NỘI - CẦN THƠ - SÓC TRĂNG (ĂN TỐI)\n",
      "NGÀY 02: SÓC TRĂNG - CÔN ĐẢO (ĂN TRƯA, TỐI)\n",
      "NGÀY 03: ...\n",
      "────────────\n",
      "https://hanoitourist.vn/can-tho-cao-lanh-chau-doc-giang-can-tho\n",
      "✅ CẦN THƠ - CAO LÃNH - CHÂU ĐỐC - AN GIANG - CẦN THƠ\n",
      "📍 Ngày đi: 19/04, 17/05, 20/06/2025... (4 ngày 3 đêm) | 📅 Hành trình: Cần Thơ - TP. Hồ Chí Minh - 4 ngày 3 đêm | 💰 8,150,000đ\n",
      "📝 Lịch trình: NGÀY 1: HÀ NỘI - CẦN THƠ - CAO LÃNH (Ăn tối)\n",
      "NGÀY 2: CAO LÃNH - TRI TÔN - RỪNG TRÀM - CHÂU ĐỐC (Ăn s...\n",
      "────────────\n",
      "https://hanoitourist.vn/vinwonder-bai-tranh-lang-chai-vinh-san-ho-dong-cuu-hang-rai-vuon-nho-ninh-thuan-thap-ba-ponagar-tam\n",
      "✅ VINWONDER – BÃI TRANH – LÀNG CHÀI – VỊNH SAN HÔ ĐỒNG CỪU – HANG RÁI - VƯỜN NHO NINH THUẬN THÁP BÀ PONAGAR – TẮM BÙN I’RESORT\n",
      "📍 Ngày đi: 21/04, 18/05, 20/05/2025... (4 ngày 3 đêm) | 📅 Hành trình: Nha Trang - 4 ngày 3 đêm | 💰 5,990,000đ\n",
      "📝 Lịch trình: NGÀY 1: HÀ NỘI – NHA TRANG – CHÙA LONG SƠN (ĂN TỐI)\n",
      "NGÀY 2: VUI CHƠI VINPEARL NHA TRANG (ĂN SÁNG, TỐ...\n",
      "────────────\n",
      "https://hanoitourist.vn/can-tho-soc-trang-bac-lieu-ca-mau-dat-mui-tien-giang-ben-tre-tay-ninh-sai-gon\n",
      "✅ CẦN THƠ – SÓC TRĂNG – BẠC LIÊU CÀ MAU – ĐẤT MŨI – TIỀN GIANG – BẾN TRE -TÂY NINH – SÀI GÒN\n",
      "📍 Ngày đi: 22/04, 24/04, 11/05/2025... (5 ngày 4 đêm) | 📅 Hành trình: TP. Hồ Chí Minh - Cần Thơ - 5 ngày 4 đêm | 💰 9,490,000đ\n",
      "📝 Lịch trình: NGÀY 1: HÀ NỘI – CẦN THƠ – CÀ MAU (Ăn trưa, tối)\n",
      "NGÀY 2: CÀ MAU – ĐẤT MŨI – CẦN THƠ (ĂN SÁNG, TRƯA, ...\n",
      "────────────\n",
      "https://hanoitourist.vn/tra-linh-tp-tinh-tay-nga-tuyen-pho-co-cam-tu-co-long-dai-hiep-coc-hang-pac-bo-thac-ban-gioc\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from playwright.async_api import async_playwright\n",
    "import aiohttp\n",
    "import os\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "async def download_image(session, url, filename):\n",
    "    async with session.get(url) as resp:\n",
    "        if resp.status == 200:\n",
    "            with open(filename, 'wb') as f:\n",
    "                f.write(await resp.read())\n",
    "\n",
    "async def crawl_tour_detail(context, detail_url):\n",
    "    page = await context.new_page()\n",
    "    await page.goto(detail_url)\n",
    "    await page.wait_for_timeout(3000)\n",
    "\n",
    "    try:\n",
    "        itinerary_buttons = await page.locator(\"button.accordion-button\").all()\n",
    "        itinerary = \"\\n\".join([await btn.inner_text() for btn in itinerary_buttons])\n",
    "        \n",
    "\n",
    "    except:\n",
    "        itinerary = \"Không có dữ liệu lịch trình\"\n",
    "\n",
    "    try:\n",
    "        includes = await page.locator(\"div.includes\").inner_text()\n",
    "    except:\n",
    "        includes = \"Không rõ dịch vụ bao gồm\"\n",
    "\n",
    "    await page.close()\n",
    "    return {\n",
    "        \"itinerary\": itinerary,\n",
    "        \"includes\": includes\n",
    "    }\n",
    "\n",
    "async def crawl_tours():\n",
    "    async with async_playwright() as p:\n",
    "        browser = await p.chromium.launch(headless=True)\n",
    "        context = await browser.new_context()\n",
    "        page = await context.new_page()\n",
    "        base_url = \"https://hanoitourist.vn/tour-trong-nuoc\"\n",
    "        await page.goto(base_url)\n",
    "        await page.wait_for_timeout(5000)\n",
    "\n",
    "        current_page = 1\n",
    "        max_page = 1  # Đổi số trang muốn crawl tại đây\n",
    "\n",
    "        all_tours = []\n",
    "        async with aiohttp.ClientSession() as session:\n",
    "            while current_page <= max_page:\n",
    "                print(f\"🔎 Crawling page {current_page}...\")\n",
    "\n",
    "                tour_cards = await page.locator(\"div.tour-item\").all()\n",
    "\n",
    "                for i, card in enumerate(tour_cards):\n",
    "                    try:\n",
    "                        title = await card.locator(\"h3 a\").inner_text()\n",
    "                        price = await card.locator(\"div.detail-gia\").inner_text()\n",
    "                        location = await card.locator(\"div.detail-item-value >> nth=1\").inner_text()\n",
    "                        dates = await card.locator(\"div.detail-item-value >> nth=0\").inner_text()\n",
    "                        detail_url = await card.locator(\"h3 a\").get_attribute(\"href\")\n",
    "                        full_detail_url = f\"https://hanoitourist.vn{detail_url}\" if detail_url.startswith(\"/\") else detail_url\n",
    "                        print(full_detail_url)\n",
    "                        image_url = await card.locator(\"div.tour-img img\").get_attribute(\"src\")\n",
    "                        filename = f\"tour_image_{current_page}_{i+1}.jpg\"\n",
    "\n",
    "                        # if image_url:\n",
    "                        #     await download_image(session, image_url, filename)\n",
    "\n",
    "                        # Crawl chi tiết từng tour\n",
    "                        detail_data = await crawl_tour_detail(context, full_detail_url)\n",
    "\n",
    "                        tour_info = {\n",
    "                            \"title\": title,\n",
    "                            \"location\": location,\n",
    "                            \"dates\": dates,\n",
    "                            \"price\": price,\n",
    "                            \"image_url\": image_url,\n",
    "                            \"detail_url\": full_detail_url,\n",
    "                            **detail_data\n",
    "                        }\n",
    "\n",
    "                        print(f\"✅ {title}\")\n",
    "                        print(f\"📍 {location} | 📅 {dates} | 💰 {price}\")\n",
    "                        print(f\"📝 Lịch trình: {detail_data['itinerary'][:100]}...\")\n",
    "                        print(\"────────────\")\n",
    "\n",
    "                        all_tours.append(tour_info)\n",
    "                    except Exception as e:\n",
    "                        print(\"⚠️ Lỗi xử lý card:\", e)\n",
    "\n",
    "                # Tìm nút \"Trang tiếp\" để next page\n",
    "                try:\n",
    "                    next_btn = page.locator(\"a.page-link:has-text('>')\")\n",
    "                    if await next_btn.is_visible():\n",
    "                        await next_btn.click()\n",
    "                        await page.wait_for_timeout(3000)\n",
    "                        current_page += 1\n",
    "                    else:\n",
    "                        break\n",
    "                except:\n",
    "                    break\n",
    "\n",
    "        await browser.close()\n",
    "\n",
    "        print(f\"🎉 Tổng cộng thu được {len(all_tours)} tour.\")\n",
    "        \n",
    "        # Có thể lưu `all_tours` vào file CSV hoặc JSON nếu muốn.\n",
    "\n",
    "# Chạy\n",
    "await crawl_tours()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def crawl_tripadvisor_carousel_images_updated(url, num_clicks=10):\n",
    "    from playwright.async_api import async_playwright\n",
    "    from bs4 import BeautifulSoup\n",
    "    import re\n",
    "    from urllib.parse import urljoin\n",
    "\n",
    "    async with async_playwright() as p:\n",
    "        browser = await p.chromium.launch(headless=False)  # Debug bằng browser thật\n",
    "        page = await browser.new_page()\n",
    "        await page.goto(url)\n",
    "        await page.wait_for_timeout(3000)\n",
    "\n",
    "        # Scroll để hiện carousel\n",
    "        await page.evaluate(\"window.scrollBy(0, 1000)\")\n",
    "        await page.wait_for_timeout(2000)\n",
    "\n",
    "        # Click mũi tên phải nhiều lần\n",
    "        for i in range(num_clicks):\n",
    "            try:\n",
    "                next_btn = page.locator('button.pWJww')\n",
    "                if await next_btn.is_visible():\n",
    "                    await next_btn.click()\n",
    "                    await page.wait_for_timeout(800)\n",
    "                else:\n",
    "                    print(f\"[{i}] Không thấy nút next.\")\n",
    "            except Exception as e:\n",
    "                print(f\"[{i}] ❌ Không bấm được: {e}\")\n",
    "                break\n",
    "\n",
    "        html = await page.content()\n",
    "        soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "        image_urls = set()\n",
    "\n",
    "        # ✅ Quét tất cả div chứa ảnh: ZGLUM là container\n",
    "        for container in soup.select(\"div.ZGLUM\"):\n",
    "            for img in container.select(\"img\"):\n",
    "                src = img.get(\"src\") or img.get(\"data-src\") or \"\"\n",
    "                if not src:\n",
    "                    continue\n",
    "                src = re.sub(r\"-s\\d+x\\d+\", \"-s1600x1200\", src).split(\"?\")[0]\n",
    "                if not src.startswith(\"http\"):\n",
    "                    src = urljoin(\"https://www.tripadvisor.com\", src)\n",
    "                if \"icons\" in src.lower():\n",
    "                    continue\n",
    "                image_urls.add(src)\n",
    "\n",
    "            # ✅ Nếu có thẻ <source> (ảnh responsive)\n",
    "            for source in container.select(\"source\"):\n",
    "                srcset = source.get(\"srcset\", \"\")\n",
    "                for part in srcset.split(\",\"):\n",
    "                    candidate = part.strip().split(\" \")[0]\n",
    "                    candidate = re.sub(r\"-s\\d+x\\d+\", \"-s1600x1200\", candidate).split(\"?\")[0]\n",
    "                    if candidate.startswith(\"http\"):\n",
    "                        image_urls.add(candidate)\n",
    "\n",
    "        await browser.close()\n",
    "        return list(image_urls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] Không thấy nút next.\n",
      "[1] Không thấy nút next.\n",
      "[2] Không thấy nút next.\n",
      "[3] Không thấy nút next.\n",
      "[4] Không thấy nút next.\n",
      "[5] Không thấy nút next.\n",
      "[6] Không thấy nút next.\n",
      "[7] Không thấy nút next.\n",
      "[8] Không thấy nút next.\n",
      "[9] Không thấy nút next.\n",
      "[10] Không thấy nút next.\n",
      "[11] Không thấy nút next.\n",
      "[12] Không thấy nút next.\n",
      "[13] Không thấy nút next.\n",
      "[14] Không thấy nút next.\n",
      "[15] Không thấy nút next.\n",
      "[16] Không thấy nút next.\n",
      "[17] Không thấy nút next.\n",
      "[18] Không thấy nút next.\n",
      "[19] Không thấy nút next.\n",
      "🎉 Tìm được 4 ảnh:\n",
      "https://dynamic-media-cdn.tripadvisor.com/media/photo-o/2f/9b/57/24/caption.jpg\n",
      "https://dynamic-media-cdn.tripadvisor.com/media/photo-o/09/32/1d/c4/old-quarter.jpg\n",
      "https://dynamic-media-cdn.tripadvisor.com/media/photo-o/2f/9c/23/45/caption.jpg\n",
      "https://dynamic-media-cdn.tripadvisor.com/media/photo-o/2f/9b/57/23/caption.jpg\n"
     ]
    }
   ],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "url = \"https://www.tripadvisor.com/Attraction_Review-g293924-d317503-Reviews-Old_Quarter-Hanoi.html\"\n",
    "imgs = await crawl_tripadvisor_carousel_images_updated(url, num_clicks=20)\n",
    "\n",
    "print(f\"🎉 Tìm được {len(imgs)} ảnh:\")\n",
    "for img in imgs[:10]:\n",
    "    print(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "Error",
     "evalue": "It looks like you are using Playwright Sync API inside the asyncio loop.\nPlease use the Async API instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mError\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 49\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 49\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mcrawl_foody_hanoi\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpages_to_crawl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(data)\n\u001b[1;32m     51\u001b[0m     df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfoody_hanoi.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8-sig\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[1], line 10\u001b[0m, in \u001b[0;36mcrawl_foody_hanoi\u001b[0;34m(pages_to_crawl)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcrawl_foody_hanoi\u001b[39m(pages_to_crawl\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m):\n\u001b[1;32m      8\u001b[0m     results \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 10\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msync_playwright\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbrowser\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchromium\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlaunch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mheadless\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpage\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbrowser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnew_page\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/playwright/sync_api/_context_manager.py:47\u001b[0m, in \u001b[0;36mPlaywrightContextManager.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_own_loop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     46\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_loop\u001b[38;5;241m.\u001b[39mis_running():\n\u001b[0;32m---> 47\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m Error(\n\u001b[1;32m     48\u001b[0m \u001b[38;5;250m                \u001b[39m\u001b[38;5;124;03m\"\"\"It looks like you are using Playwright Sync API inside the asyncio loop.\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;124;03mPlease use the Async API instead.\"\"\"\u001b[39;00m\n\u001b[1;32m     50\u001b[0m             )\n\u001b[1;32m     52\u001b[0m         \u001b[38;5;66;03m# Create a new fiber for the protocol dispatcher. It will be pumping events\u001b[39;00m\n\u001b[1;32m     53\u001b[0m         \u001b[38;5;66;03m# until the end of times. We will pass control to that fiber every time we\u001b[39;00m\n\u001b[1;32m     54\u001b[0m         \u001b[38;5;66;03m# block while waiting for a response.\u001b[39;00m\n\u001b[1;32m     55\u001b[0m         \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgreenlet_main\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mError\u001b[0m: It looks like you are using Playwright Sync API inside the asyncio loop.\nPlease use the Async API instead."
     ]
    }
   ],
   "source": [
    "# crawl_foody_hanoi.py\n",
    "\n",
    "from playwright.sync_api import sync_playwright\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "def crawl_foody_hanoi(pages_to_crawl=3):\n",
    "    results = []\n",
    "\n",
    "    with sync_playwright() as p:\n",
    "        browser = p.chromium.launch(headless=True)\n",
    "        page = browser.new_page()\n",
    "        base_url = \"https://www.foody.vn/ha-noi/dia-diem?page=\"\n",
    "\n",
    "        for i in range(1, pages_to_crawl + 1):\n",
    "            print(f\"Crawling page {i}...\")\n",
    "            page.goto(base_url + str(i), timeout=60000)\n",
    "            page.wait_for_timeout(5000)\n",
    "\n",
    "            items = page.query_selector_all(\"div.result-group > div[data-view-id]\")\n",
    "            for item in items:\n",
    "                try:\n",
    "                    name = item.query_selector(\"h2 > a\").inner_text().strip()\n",
    "                    url = item.query_selector(\"h2 > a\").get_attribute(\"href\")\n",
    "                    full_url = \"https://www.foody.vn\" + url\n",
    "\n",
    "                    address = item.query_selector(\".result-address\").inner_text().strip()\n",
    "                    rating = item.query_selector(\".point.highlight\").inner_text().strip() if item.query_selector(\".point.highlight\") else \"N/A\"\n",
    "                    category = item.query_selector(\".detail-info\").inner_text().strip() if item.query_selector(\".detail-info\") else \"N/A\"\n",
    "                    img_url = item.query_selector(\"img\").get_attribute(\"src\")\n",
    "\n",
    "                    results.append({\n",
    "                        \"Tên\": name,\n",
    "                        \"Địa chỉ\": address,\n",
    "                        \"Điểm\": rating,\n",
    "                        \"Loại hình\": category,\n",
    "                        \"Link ảnh\": img_url,\n",
    "                        \"Foody URL\": full_url\n",
    "                    })\n",
    "                except Exception as e:\n",
    "                    print(f\"❌ Error on item: {e}\")\n",
    "                    continue\n",
    "\n",
    "        browser.close()\n",
    "\n",
    "    return results\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    data = crawl_foody_hanoi(pages_to_crawl=5)\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_csv(\"foody_hanoi.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "    print(\"✅ Đã lưu kết quả vào foody_hanoi.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
